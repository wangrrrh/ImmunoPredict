{
  "best_metric": 0.776242196559906,
  "best_model_checkpoint": "/public8/lilab/student/rhwang/geneformer/model/my_model/2407030113_42_5_geneformer_DiseaseClassifier_bcc/checkpoint-110",
  "epoch": 1.0091743119266054,
  "eval_steps": 11,
  "global_step": 110,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009174311926605505,
      "grad_norm": 2.365508556365967,
      "learning_rate": 4.984709480122324e-05,
      "loss": 0.7096,
      "step": 1
    },
    {
      "epoch": 0.01834862385321101,
      "grad_norm": 2.270963668823242,
      "learning_rate": 4.9694189602446484e-05,
      "loss": 0.6762,
      "step": 2
    },
    {
      "epoch": 0.027522935779816515,
      "grad_norm": 0.6618096232414246,
      "learning_rate": 4.954128440366973e-05,
      "loss": 0.683,
      "step": 3
    },
    {
      "epoch": 0.03669724770642202,
      "grad_norm": 1.1500492095947266,
      "learning_rate": 4.938837920489297e-05,
      "loss": 0.6502,
      "step": 4
    },
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 0.8537439107894897,
      "learning_rate": 4.923547400611621e-05,
      "loss": 0.6508,
      "step": 5
    },
    {
      "epoch": 0.05504587155963303,
      "grad_norm": 0.7113690972328186,
      "learning_rate": 4.9082568807339454e-05,
      "loss": 0.6395,
      "step": 6
    },
    {
      "epoch": 0.06422018348623854,
      "grad_norm": 1.6232779026031494,
      "learning_rate": 4.892966360856269e-05,
      "loss": 0.733,
      "step": 7
    },
    {
      "epoch": 0.07339449541284404,
      "grad_norm": 0.6982094049453735,
      "learning_rate": 4.8776758409785936e-05,
      "loss": 0.6005,
      "step": 8
    },
    {
      "epoch": 0.08256880733944955,
      "grad_norm": 0.5079002976417542,
      "learning_rate": 4.862385321100918e-05,
      "loss": 0.6106,
      "step": 9
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 0.5000748038291931,
      "learning_rate": 4.847094801223242e-05,
      "loss": 0.6368,
      "step": 10
    },
    {
      "epoch": 0.10091743119266056,
      "grad_norm": 0.9940968751907349,
      "learning_rate": 4.831804281345566e-05,
      "loss": 0.5447,
      "step": 11
    },
    {
      "epoch": 0.10091743119266056,
      "eval_accuracy": 0.6704225352112676,
      "eval_auc": 0.3480841054370466,
      "eval_f1": 0.5381469253972401,
      "eval_loss": 0.9450602531433105,
      "eval_runtime": 68.5642,
      "eval_samples_per_second": 10.355,
      "eval_steps_per_second": 0.175,
      "step": 11
    },
    {
      "epoch": 0.11009174311926606,
      "grad_norm": 0.6794050335884094,
      "learning_rate": 4.81651376146789e-05,
      "loss": 0.637,
      "step": 12
    },
    {
      "epoch": 0.11926605504587157,
      "grad_norm": 0.9782084226608276,
      "learning_rate": 4.8012232415902144e-05,
      "loss": 0.6818,
      "step": 13
    },
    {
      "epoch": 0.12844036697247707,
      "grad_norm": 0.5935295820236206,
      "learning_rate": 4.785932721712538e-05,
      "loss": 0.633,
      "step": 14
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 0.6589301824569702,
      "learning_rate": 4.7706422018348626e-05,
      "loss": 0.6415,
      "step": 15
    },
    {
      "epoch": 0.14678899082568808,
      "grad_norm": 1.0106182098388672,
      "learning_rate": 4.755351681957187e-05,
      "loss": 0.6752,
      "step": 16
    },
    {
      "epoch": 0.1559633027522936,
      "grad_norm": 0.47619175910949707,
      "learning_rate": 4.740061162079511e-05,
      "loss": 0.6319,
      "step": 17
    },
    {
      "epoch": 0.1651376146788991,
      "grad_norm": 0.5182163119316101,
      "learning_rate": 4.724770642201835e-05,
      "loss": 0.6238,
      "step": 18
    },
    {
      "epoch": 0.1743119266055046,
      "grad_norm": 0.27899646759033203,
      "learning_rate": 4.709480122324159e-05,
      "loss": 0.624,
      "step": 19
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 0.32878759503364563,
      "learning_rate": 4.694189602446483e-05,
      "loss": 0.602,
      "step": 20
    },
    {
      "epoch": 0.1926605504587156,
      "grad_norm": 0.8749052882194519,
      "learning_rate": 4.678899082568808e-05,
      "loss": 0.6482,
      "step": 21
    },
    {
      "epoch": 0.2018348623853211,
      "grad_norm": 0.36736199259757996,
      "learning_rate": 4.663608562691132e-05,
      "loss": 0.6381,
      "step": 22
    },
    {
      "epoch": 0.2018348623853211,
      "eval_accuracy": 0.6014084507042253,
      "eval_auc": 0.3070773181067299,
      "eval_f1": 0.5075582463848598,
      "eval_loss": 0.8939960598945618,
      "eval_runtime": 67.2388,
      "eval_samples_per_second": 10.559,
      "eval_steps_per_second": 0.178,
      "step": 22
    },
    {
      "epoch": 0.21100917431192662,
      "grad_norm": 0.484608918428421,
      "learning_rate": 4.648318042813456e-05,
      "loss": 0.591,
      "step": 23
    },
    {
      "epoch": 0.22018348623853212,
      "grad_norm": 0.7889516949653625,
      "learning_rate": 4.6330275229357804e-05,
      "loss": 0.5815,
      "step": 24
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 0.31271082162857056,
      "learning_rate": 4.617737003058104e-05,
      "loss": 0.6533,
      "step": 25
    },
    {
      "epoch": 0.23853211009174313,
      "grad_norm": 0.6433531045913696,
      "learning_rate": 4.602446483180428e-05,
      "loss": 0.5998,
      "step": 26
    },
    {
      "epoch": 0.24770642201834864,
      "grad_norm": 0.35363060235977173,
      "learning_rate": 4.587155963302753e-05,
      "loss": 0.6537,
      "step": 27
    },
    {
      "epoch": 0.25688073394495414,
      "grad_norm": 1.2112841606140137,
      "learning_rate": 4.571865443425077e-05,
      "loss": 0.5865,
      "step": 28
    },
    {
      "epoch": 0.26605504587155965,
      "grad_norm": 1.8108545541763306,
      "learning_rate": 4.556574923547401e-05,
      "loss": 0.6943,
      "step": 29
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 0.4846499562263489,
      "learning_rate": 4.541284403669725e-05,
      "loss": 0.6233,
      "step": 30
    },
    {
      "epoch": 0.28440366972477066,
      "grad_norm": 1.1968965530395508,
      "learning_rate": 4.525993883792049e-05,
      "loss": 0.6711,
      "step": 31
    },
    {
      "epoch": 0.29357798165137616,
      "grad_norm": 0.5748723745346069,
      "learning_rate": 4.510703363914373e-05,
      "loss": 0.6175,
      "step": 32
    },
    {
      "epoch": 0.30275229357798167,
      "grad_norm": 1.0614278316497803,
      "learning_rate": 4.4954128440366975e-05,
      "loss": 0.6081,
      "step": 33
    },
    {
      "epoch": 0.30275229357798167,
      "eval_accuracy": 0.4295774647887324,
      "eval_auc": 0.3463962508080155,
      "eval_f1": 0.4343889013556503,
      "eval_loss": 0.8463433980941772,
      "eval_runtime": 67.2094,
      "eval_samples_per_second": 10.564,
      "eval_steps_per_second": 0.179,
      "step": 33
    },
    {
      "epoch": 0.3119266055045872,
      "grad_norm": 0.5820510983467102,
      "learning_rate": 4.480122324159022e-05,
      "loss": 0.6449,
      "step": 34
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 0.846648097038269,
      "learning_rate": 4.4648318042813456e-05,
      "loss": 0.6173,
      "step": 35
    },
    {
      "epoch": 0.3302752293577982,
      "grad_norm": 0.5920421481132507,
      "learning_rate": 4.44954128440367e-05,
      "loss": 0.6117,
      "step": 36
    },
    {
      "epoch": 0.3394495412844037,
      "grad_norm": 1.1606968641281128,
      "learning_rate": 4.434250764525994e-05,
      "loss": 0.5953,
      "step": 37
    },
    {
      "epoch": 0.3486238532110092,
      "grad_norm": 1.7128820419311523,
      "learning_rate": 4.418960244648318e-05,
      "loss": 0.5903,
      "step": 38
    },
    {
      "epoch": 0.3577981651376147,
      "grad_norm": 1.5910098552703857,
      "learning_rate": 4.403669724770643e-05,
      "loss": 0.6043,
      "step": 39
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 1.2311006784439087,
      "learning_rate": 4.3883792048929664e-05,
      "loss": 0.5778,
      "step": 40
    },
    {
      "epoch": 0.3761467889908257,
      "grad_norm": 1.7542067766189575,
      "learning_rate": 4.373088685015291e-05,
      "loss": 0.6465,
      "step": 41
    },
    {
      "epoch": 0.3853211009174312,
      "grad_norm": 0.972960889339447,
      "learning_rate": 4.3577981651376146e-05,
      "loss": 0.5787,
      "step": 42
    },
    {
      "epoch": 0.3944954128440367,
      "grad_norm": 2.806267261505127,
      "learning_rate": 4.342507645259939e-05,
      "loss": 0.7111,
      "step": 43
    },
    {
      "epoch": 0.4036697247706422,
      "grad_norm": 1.9724698066711426,
      "learning_rate": 4.327217125382263e-05,
      "loss": 0.6638,
      "step": 44
    },
    {
      "epoch": 0.4036697247706422,
      "eval_accuracy": 0.5253521126760563,
      "eval_auc": 0.31604180133591897,
      "eval_f1": 0.4722187819778038,
      "eval_loss": 0.9160788655281067,
      "eval_runtime": 66.2994,
      "eval_samples_per_second": 10.709,
      "eval_steps_per_second": 0.181,
      "step": 44
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 1.8428188562393188,
      "learning_rate": 4.311926605504588e-05,
      "loss": 0.6615,
      "step": 45
    },
    {
      "epoch": 0.42201834862385323,
      "grad_norm": 0.47439032793045044,
      "learning_rate": 4.2966360856269116e-05,
      "loss": 0.5746,
      "step": 46
    },
    {
      "epoch": 0.43119266055045874,
      "grad_norm": 1.5956950187683105,
      "learning_rate": 4.281345565749236e-05,
      "loss": 0.6549,
      "step": 47
    },
    {
      "epoch": 0.44036697247706424,
      "grad_norm": 0.3655122220516205,
      "learning_rate": 4.26605504587156e-05,
      "loss": 0.5917,
      "step": 48
    },
    {
      "epoch": 0.44954128440366975,
      "grad_norm": 1.9467767477035522,
      "learning_rate": 4.2507645259938835e-05,
      "loss": 0.6445,
      "step": 49
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 0.8558526039123535,
      "learning_rate": 4.235474006116208e-05,
      "loss": 0.5655,
      "step": 50
    },
    {
      "epoch": 0.46788990825688076,
      "grad_norm": 0.8705873489379883,
      "learning_rate": 4.2201834862385324e-05,
      "loss": 0.6138,
      "step": 51
    },
    {
      "epoch": 0.47706422018348627,
      "grad_norm": 1.0109928846359253,
      "learning_rate": 4.204892966360857e-05,
      "loss": 0.6385,
      "step": 52
    },
    {
      "epoch": 0.48623853211009177,
      "grad_norm": 2.6906964778900146,
      "learning_rate": 4.1896024464831806e-05,
      "loss": 0.7061,
      "step": 53
    },
    {
      "epoch": 0.4954128440366973,
      "grad_norm": 0.8310309052467346,
      "learning_rate": 4.174311926605505e-05,
      "loss": 0.5869,
      "step": 54
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 2.7789394855499268,
      "learning_rate": 4.159021406727829e-05,
      "loss": 0.5648,
      "step": 55
    },
    {
      "epoch": 0.5045871559633027,
      "eval_accuracy": 0.4112676056338028,
      "eval_auc": 0.34380611218846513,
      "eval_f1": 0.42572198861365107,
      "eval_loss": 0.8241293430328369,
      "eval_runtime": 66.4552,
      "eval_samples_per_second": 10.684,
      "eval_steps_per_second": 0.181,
      "step": 55
    },
    {
      "epoch": 0.5137614678899083,
      "grad_norm": 1.7398831844329834,
      "learning_rate": 4.143730886850153e-05,
      "loss": 0.5567,
      "step": 56
    },
    {
      "epoch": 0.5229357798165137,
      "grad_norm": 2.5738914012908936,
      "learning_rate": 4.1284403669724776e-05,
      "loss": 0.595,
      "step": 57
    },
    {
      "epoch": 0.5321100917431193,
      "grad_norm": 0.47113385796546936,
      "learning_rate": 4.1131498470948013e-05,
      "loss": 0.6212,
      "step": 58
    },
    {
      "epoch": 0.5412844036697247,
      "grad_norm": 0.959870457649231,
      "learning_rate": 4.097859327217126e-05,
      "loss": 0.613,
      "step": 59
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 2.5479485988616943,
      "learning_rate": 4.0825688073394495e-05,
      "loss": 0.6634,
      "step": 60
    },
    {
      "epoch": 0.5596330275229358,
      "grad_norm": 0.9266079664230347,
      "learning_rate": 4.067278287461774e-05,
      "loss": 0.611,
      "step": 61
    },
    {
      "epoch": 0.5688073394495413,
      "grad_norm": 2.03003191947937,
      "learning_rate": 4.051987767584098e-05,
      "loss": 0.6396,
      "step": 62
    },
    {
      "epoch": 0.5779816513761468,
      "grad_norm": 0.4437566101551056,
      "learning_rate": 4.036697247706422e-05,
      "loss": 0.6172,
      "step": 63
    },
    {
      "epoch": 0.5871559633027523,
      "grad_norm": 0.6596472263336182,
      "learning_rate": 4.0214067278287465e-05,
      "loss": 0.5995,
      "step": 64
    },
    {
      "epoch": 0.5963302752293578,
      "grad_norm": 0.7441666722297668,
      "learning_rate": 4.00611620795107e-05,
      "loss": 0.6035,
      "step": 65
    },
    {
      "epoch": 0.6055045871559633,
      "grad_norm": 0.8331594467163086,
      "learning_rate": 3.990825688073395e-05,
      "loss": 0.581,
      "step": 66
    },
    {
      "epoch": 0.6055045871559633,
      "eval_accuracy": 0.4535211267605634,
      "eval_auc": 0.3164368311427135,
      "eval_f1": 0.4476619718309859,
      "eval_loss": 0.8409200310707092,
      "eval_runtime": 66.3967,
      "eval_samples_per_second": 10.693,
      "eval_steps_per_second": 0.181,
      "step": 66
    },
    {
      "epoch": 0.6146788990825688,
      "grad_norm": 0.682941198348999,
      "learning_rate": 3.9755351681957185e-05,
      "loss": 0.5659,
      "step": 67
    },
    {
      "epoch": 0.6238532110091743,
      "grad_norm": 1.014488935470581,
      "learning_rate": 3.960244648318043e-05,
      "loss": 0.5759,
      "step": 68
    },
    {
      "epoch": 0.6330275229357798,
      "grad_norm": 2.1358320713043213,
      "learning_rate": 3.944954128440367e-05,
      "loss": 0.6306,
      "step": 69
    },
    {
      "epoch": 0.6422018348623854,
      "grad_norm": 0.8828741312026978,
      "learning_rate": 3.929663608562692e-05,
      "loss": 0.5978,
      "step": 70
    },
    {
      "epoch": 0.6513761467889908,
      "grad_norm": 1.6709260940551758,
      "learning_rate": 3.9143730886850155e-05,
      "loss": 0.659,
      "step": 71
    },
    {
      "epoch": 0.6605504587155964,
      "grad_norm": 0.8814018368721008,
      "learning_rate": 3.89908256880734e-05,
      "loss": 0.6133,
      "step": 72
    },
    {
      "epoch": 0.6697247706422018,
      "grad_norm": 0.8697484731674194,
      "learning_rate": 3.8837920489296637e-05,
      "loss": 0.5664,
      "step": 73
    },
    {
      "epoch": 0.6788990825688074,
      "grad_norm": 1.8489494323730469,
      "learning_rate": 3.8685015290519874e-05,
      "loss": 0.5622,
      "step": 74
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 1.174920916557312,
      "learning_rate": 3.8532110091743125e-05,
      "loss": 0.5388,
      "step": 75
    },
    {
      "epoch": 0.6972477064220184,
      "grad_norm": 1.325819492340088,
      "learning_rate": 3.837920489296636e-05,
      "loss": 0.6006,
      "step": 76
    },
    {
      "epoch": 0.7064220183486238,
      "grad_norm": 2.9101169109344482,
      "learning_rate": 3.822629969418961e-05,
      "loss": 0.5813,
      "step": 77
    },
    {
      "epoch": 0.7064220183486238,
      "eval_accuracy": 0.46901408450704224,
      "eval_auc": 0.2907958055016879,
      "eval_f1": 0.45275328532796466,
      "eval_loss": 0.8685699105262756,
      "eval_runtime": 67.2464,
      "eval_samples_per_second": 10.558,
      "eval_steps_per_second": 0.178,
      "step": 77
    },
    {
      "epoch": 0.7155963302752294,
      "grad_norm": 1.251329779624939,
      "learning_rate": 3.8073394495412844e-05,
      "loss": 0.5697,
      "step": 78
    },
    {
      "epoch": 0.7247706422018348,
      "grad_norm": 3.8792598247528076,
      "learning_rate": 3.792048929663609e-05,
      "loss": 0.632,
      "step": 79
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 2.0367624759674072,
      "learning_rate": 3.7767584097859326e-05,
      "loss": 0.5436,
      "step": 80
    },
    {
      "epoch": 0.7431192660550459,
      "grad_norm": 1.3027669191360474,
      "learning_rate": 3.761467889908257e-05,
      "loss": 0.5636,
      "step": 81
    },
    {
      "epoch": 0.7522935779816514,
      "grad_norm": 0.9666320085525513,
      "learning_rate": 3.7461773700305815e-05,
      "loss": 0.5892,
      "step": 82
    },
    {
      "epoch": 0.7614678899082569,
      "grad_norm": 5.178908348083496,
      "learning_rate": 3.730886850152905e-05,
      "loss": 0.5143,
      "step": 83
    },
    {
      "epoch": 0.7706422018348624,
      "grad_norm": 4.347674369812012,
      "learning_rate": 3.7155963302752296e-05,
      "loss": 0.5523,
      "step": 84
    },
    {
      "epoch": 0.7798165137614679,
      "grad_norm": 8.295042037963867,
      "learning_rate": 3.7003058103975534e-05,
      "loss": 0.5332,
      "step": 85
    },
    {
      "epoch": 0.7889908256880734,
      "grad_norm": 1.5943750143051147,
      "learning_rate": 3.685015290519878e-05,
      "loss": 0.6297,
      "step": 86
    },
    {
      "epoch": 0.7981651376146789,
      "grad_norm": 1.2985268831253052,
      "learning_rate": 3.669724770642202e-05,
      "loss": 0.6319,
      "step": 87
    },
    {
      "epoch": 0.8073394495412844,
      "grad_norm": 1.9532067775726318,
      "learning_rate": 3.654434250764526e-05,
      "loss": 0.5934,
      "step": 88
    },
    {
      "epoch": 0.8073394495412844,
      "eval_accuracy": 0.46619718309859154,
      "eval_auc": 0.27958683473389356,
      "eval_f1": 0.4524371068166636,
      "eval_loss": 0.855782687664032,
      "eval_runtime": 67.2312,
      "eval_samples_per_second": 10.561,
      "eval_steps_per_second": 0.178,
      "step": 88
    },
    {
      "epoch": 0.8165137614678899,
      "grad_norm": 1.0782442092895508,
      "learning_rate": 3.6391437308868504e-05,
      "loss": 0.5597,
      "step": 89
    },
    {
      "epoch": 0.8256880733944955,
      "grad_norm": 0.6128043532371521,
      "learning_rate": 3.623853211009174e-05,
      "loss": 0.5607,
      "step": 90
    },
    {
      "epoch": 0.8348623853211009,
      "grad_norm": 4.858972072601318,
      "learning_rate": 3.6085626911314986e-05,
      "loss": 0.5765,
      "step": 91
    },
    {
      "epoch": 0.8440366972477065,
      "grad_norm": 7.786489009857178,
      "learning_rate": 3.593272171253822e-05,
      "loss": 0.6866,
      "step": 92
    },
    {
      "epoch": 0.8532110091743119,
      "grad_norm": 3.3974714279174805,
      "learning_rate": 3.5779816513761474e-05,
      "loss": 0.5714,
      "step": 93
    },
    {
      "epoch": 0.8623853211009175,
      "grad_norm": 2.5702998638153076,
      "learning_rate": 3.562691131498471e-05,
      "loss": 0.5831,
      "step": 94
    },
    {
      "epoch": 0.8715596330275229,
      "grad_norm": 1.4649381637573242,
      "learning_rate": 3.5474006116207956e-05,
      "loss": 0.5841,
      "step": 95
    },
    {
      "epoch": 0.8807339449541285,
      "grad_norm": 6.592377185821533,
      "learning_rate": 3.5321100917431193e-05,
      "loss": 0.7184,
      "step": 96
    },
    {
      "epoch": 0.8899082568807339,
      "grad_norm": 6.126465320587158,
      "learning_rate": 3.516819571865443e-05,
      "loss": 0.4618,
      "step": 97
    },
    {
      "epoch": 0.8990825688073395,
      "grad_norm": 2.6586754322052,
      "learning_rate": 3.5015290519877675e-05,
      "loss": 0.586,
      "step": 98
    },
    {
      "epoch": 0.908256880733945,
      "grad_norm": 1.6481808423995972,
      "learning_rate": 3.486238532110092e-05,
      "loss": 0.5829,
      "step": 99
    },
    {
      "epoch": 0.908256880733945,
      "eval_accuracy": 0.45774647887323944,
      "eval_auc": 0.28166971916971917,
      "eval_f1": 0.4501289963926457,
      "eval_loss": 0.8364855051040649,
      "eval_runtime": 66.917,
      "eval_samples_per_second": 10.61,
      "eval_steps_per_second": 0.179,
      "step": 99
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 3.6504225730895996,
      "learning_rate": 3.4709480122324164e-05,
      "loss": 0.5062,
      "step": 100
    },
    {
      "epoch": 0.926605504587156,
      "grad_norm": 2.073798418045044,
      "learning_rate": 3.45565749235474e-05,
      "loss": 0.5297,
      "step": 101
    },
    {
      "epoch": 0.9357798165137615,
      "grad_norm": 9.361923217773438,
      "learning_rate": 3.4403669724770645e-05,
      "loss": 0.7087,
      "step": 102
    },
    {
      "epoch": 0.944954128440367,
      "grad_norm": 7.209685325622559,
      "learning_rate": 3.425076452599388e-05,
      "loss": 0.547,
      "step": 103
    },
    {
      "epoch": 0.9541284403669725,
      "grad_norm": 1.8333238363265991,
      "learning_rate": 3.409785932721713e-05,
      "loss": 0.5646,
      "step": 104
    },
    {
      "epoch": 0.963302752293578,
      "grad_norm": 0.8013563752174377,
      "learning_rate": 3.394495412844037e-05,
      "loss": 0.5585,
      "step": 105
    },
    {
      "epoch": 0.9724770642201835,
      "grad_norm": 2.0188257694244385,
      "learning_rate": 3.379204892966361e-05,
      "loss": 0.6487,
      "step": 106
    },
    {
      "epoch": 0.981651376146789,
      "grad_norm": 3.119746208190918,
      "learning_rate": 3.363914373088685e-05,
      "loss": 0.6158,
      "step": 107
    },
    {
      "epoch": 0.9908256880733946,
      "grad_norm": 0.8293989300727844,
      "learning_rate": 3.348623853211009e-05,
      "loss": 0.5986,
      "step": 108
    },
    {
      "epoch": 1.0,
      "grad_norm": 16.58962059020996,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.6403,
      "step": 109
    },
    {
      "epoch": 1.0091743119266054,
      "grad_norm": 5.059521675109863,
      "learning_rate": 3.318042813455658e-05,
      "loss": 0.5471,
      "step": 110
    },
    {
      "epoch": 1.0091743119266054,
      "eval_accuracy": 0.423943661971831,
      "eval_auc": 0.2833710407239819,
      "eval_f1": 0.43379617158677064,
      "eval_loss": 0.776242196559906,
      "eval_runtime": 66.5487,
      "eval_samples_per_second": 10.669,
      "eval_steps_per_second": 0.18,
      "step": 110
    }
  ],
  "logging_steps": 1,
  "max_steps": 327,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 11,
  "total_flos": 277602856058880.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
